---
title: "Air Pollution in Seoul"
author: "Daniel Chen"
date: "4/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract

## Introduction

## Results

blah blah balh validation of input and summary

First, we load all necessary packages for this analysis.

```{r, warning = FALSE, echo = FALSE, message = FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(lubridate)
library(knitr)
library(kableExtra)
library(geojsonio)
library(gridExtra)
library(forecast)
```


```{r load_data, echo = FALSE}
# Load data
measurement_summary <- data.table::fread("input/AirPollutionSeoul/Measurement_summary.csv")
measurement_info <- data.table::fread("input/AirPollutionSeoul/Original Data/Measurement_info.csv")
measurement_item_info <- data.table::fread("input/AirPollutionSeoul/Original Data/Measurement_item_info.csv")
measurement_station_info <- data.table::fread("input/AirPollutionSeoul/Original Data/Measurement_station_info.csv")
```

```{r create_explanation_df, echo = FALSE}
measurement_summary_explaination <- data.frame(Variables = c("Measurement Date", "Station code", "Address", "Latitude", "Longitude", "SO2", "NO2", "O3", "CO", "PM10", "PM2.5"), 
                                               Explaination = c("Date of Measurement", "Station code", "Address of monitoring station", "Latitude of station", "Longitude of station", "Average Sulfur Dioxide(ppm)", "Average Nitrogen Dioxide(ppm)", "Average Ozone(ppm)", "Average Carbon Monoxide(ppm)", "Average Particulate Matter 10µg or less (µg/m^3)", "Average Particulate Matter 2.5µg or less(µg/m^3 )"))

measurement_info_explanation <- data.frame(Variables = c("Measurement Date", "Station Code", "Item Code", "Average Value", "Instrument Status"), 
                                           Explanation = c("Measurement Date", "Station Code Primary key", "Item Code Primary Key", "Average value for given item code", "Status of instrument"))

measurement_item_info_explaination <- data.frame(Variables = c("Item code", "Item name", "Unit of measurement", "Good(blue)", "Normal(green)", "Bad(yellow)", "Very bad(Red)"), 
                                                 Explaination = c("Item code primary key", "Measured item name", "Unit of measurement", "Good value", "Normal value", "Bad value", "Very bad value"))

measurement_station_info_explaination <- data.frame(Variables = c("Station code", "Station name(district)", "Address", "Latitude", "Longitude"), 
                                                    Explaination = c("Station code primary key", "District name for station", "Address of station", "Latitude", "Longitude"))
```

### Dataset Summary

There are four datasets in this analysis. One is the summary and the others are elements used to help build the summary. The variable keys for the datasets can be seen below.   

#### Variable Keys
##### Measurement Summary
```{r, echo = FALSE}
kable(measurement_summary_explaination) %>% kable_styling()
```

#### Measurement Info
```{r, echo = FALSE}
kable(measurement_info_explanation) %>% kable_styling()
```


#### Measurement Item Info
```{r, echo = FALSE}
kable(measurement_item_info_explaination) %>% kable_styling()
```

#### Measurement Station Info
```{r, echo = FALSE}
kable(measurement_station_info_explaination) %>% kable_styling()
```

### Exploratory Data Analysis

```{r, echo = FALSE}
# Fixing variable types
measurement_summary <- measurement_summary %>% mutate(`Measurement date` = as.POSIXct(`Measurement date`, tz = "GMT"), `Station code` = as.factor(`Station code`), Address = as.factor(Address) )
```

```{r, echo = FALSE}
summary(measurement_summary)
```

We take a quick loko at the data to understand how the summary is laid out. The data looks like a wide data format of various measurement values across 3 years from multiple locations.

```{r maps, echo = FALSE, warnings = FALSE, message = FALSE}
# Load data
spdf1 <- geojson_read("input/seoul_municipalities_geo_simple.json",  what = "sp")
spdf2 <- geojson_read("input/seoul_submunicipalities_geo_simple.json",  what = "sp")

# Prep ggplot for plotting
library(broom)
spdf_fortified <- tidy(spdf1)
ggplot() +
  geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill="#69b3a2", color="white") +
  geom_point(data = measurement_station_info, aes(x = Longitude, y = Latitude), size = 4, shape = 23, fill = "darkred") +
  theme_void() +
  coord_map()
```

The figure above is a plot of Seoul with the lines representing the divisions between different municipalities. The red diamonds show the location of the `r levels(measurement_summary[,2]) %>% length` monitoring stations in this study. 

```{r, echo = FALSE}
# Using average across all stations to save compute
measurement_summary_long <- gather(measurement_summary, Measurement, Value, SO2:PM2.5) %>% group_by(`Measurement 
```

```{r, echo = FALSE}
date`, Measurement) %>% summarise(Average = mean(Value))
ggplot(measurement_summary_long %>% filter(Measurement %in% c("PM10", "PM2.5")), aes(x = `Measurement date`, y = Average, color = Measurement)) + geom_line() + ggtitle("Average Particulate Matter(ug/m^3) Measurements over time") + ylab("Average(ug/m^3)")
```

The plot above shows the average particulate matter value over the course of about three years. In general, it looks like PM10 has higher measured values.

```{r, echo = FALSE}
ggplot(measurement_summary_long %>% filter(Measurement %in% c("SO2", "NO2", "O3", "CO")), aes(x = `Measurement date`, y = Average, color = Measurement)) + geom_line() + ggtitle("Average Chemical Compound(ppm) Measurements over time") + ylab("Average(ppm)")
```

We can see in this plot above that the highest measured values out of the chemicals is Carbon monoxide. The other measurements are smaller and deviations can be seen including what appear to be measurement errors as they are below 0. There seemed to have been some sort of sensor malfunction around Fall of 2019 and some major spikes especially in 2019. 

```{r, echo = FALSE}
p1_2019 <- ggplot(measurement_summary_long %>% filter(Measurement %in% c("SO2", "NO2", "O3", "CO")) %>% filter(`Measurement date` > ymd(20190101)), aes(x = `Measurement date`, y = Average, color = Measurement)) + geom_line() + ggtitle("Average Chemical Compound(ppm) Measurements in 2019") + ylab("Average(ppm)")
p2_2019 <- ggplot(measurement_summary_long %>% filter(Measurement %in% c("PM10", "PM2.5")) %>% filter(`Measurement date` > ymd(20190101)), aes(x = `Measurement date`, y = Average, color = Measurement)) + geom_line() + ggtitle("Average Particulate Matter(ug/m^3) Measurements in 2019") + ylab("Average(ug/m^3)")
grid.arrange(p1_2019, p2_2019, nrow = 2)
```

We try to examine 2019 a bit more closer. There was a cyclical event at around early March which caused a spike in polution levels in both the chemical level and particle level. The pollution levels look somewhat seasonal as it looks like CO levels are higher during the mid fall to early spring. 

```{r}
measurement_summary_wide <- spread(measurement_summary_long, Measurement, Average)
pairs(measurement_summary_wide %>% select(-`Measurement date`))
```

We look at the pairwise plot fo the average measurements. It looks like in general that everything is positively correlated although some pairwise correlations do look more nonlinear in nature like  with CO and NO2.. 

```{r}
measurement_summary_ts <- ts(measurement_summary_wide, start = 2017, end = 2020, frequency = 1)
```


## Discussion

## Acknowledgements
I would like to acknowledge Prof. Parzen and the teaching assitants of Stat 109 for teaching the course. Additionally, I would like to acknowledge bappe, Kaggle, and the Korean government for releasing this dataset.


## References
probably whatever package i need